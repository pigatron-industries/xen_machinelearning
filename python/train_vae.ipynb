{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 15:41:41.052612: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 385 files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f96a1d1dfdb434fbfc0c36f3995a44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=385)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298d536115a44e2ebb50410c623e9181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 385 songs\n",
      "Filtered to 95 songs\n",
      "Ignored 20 sequences from ../../../ai/trainingdata/music/mutopia_guitar/Matiegka3.mid\n",
      "Ignored 2 sequences from ../../../ai/trainingdata/music/mutopia_guitar/capricho-arabe.mid\n",
      "Ignored 24 sequences from ../../../ai/trainingdata/music/mutopia_guitar/carcassi-op60-03.mid\n",
      "Ignored 3 sequences from ../../../ai/trainingdata/music/mutopia_guitar/horetzky29.mid\n",
      "Ignored 84 sequences from ../../../ai/trainingdata/music/mutopia_guitar/sorf-op6n11.mid\n",
      "Ignored 42 sequences from ../../../ai/trainingdata/music/mutopia_guitar/sorf-op6n07.mid\n",
      "Ignored 69 sequences from ../../../ai/trainingdata/music/mutopia_guitar/claro-de-luna.mid\n",
      "Ignored 70 sequences from ../../../ai/trainingdata/music/mutopia_guitar/moonlight-guitar-duo.mid\n",
      "Ignored 1 sequences from ../../../ai/trainingdata/music/mutopia_guitar/bwv-1006a_3g.mid\n",
      "Ignored 1 sequences from ../../../ai/trainingdata/music/mutopia_guitar/guitar-skole-no-09.mid\n",
      "Ignored 2 sequences from ../../../ai/trainingdata/music/mutopia_guitar/Sor_Etude_Opus35_14.mid\n",
      "Ignored 1 sequences from ../../../ai/trainingdata/music/mutopia_guitar/guitar-skole-no-05.mid\n",
      "Ignored 4 sequences from ../../../ai/trainingdata/music/mutopia_guitar/guitar-skole-no-16.mid\n",
      "Ignored 1 sequences from ../../../ai/trainingdata/music/mutopia_guitar/bach_air_bmv_1068.mid\n",
      "Ignored 3 sequences from ../../../ai/trainingdata/music/mutopia_guitar/guitar-skole-no-14.mid\n",
      "Ignored 32 sequences from ../../../ai/trainingdata/music/mutopia_guitar/SixStudiesA.mid\n",
      "Sparse sequences shape: (3159, 16, 128)\n",
      "Lowest note: 38, Highest note: 94\n",
      "Trimmed sequences shape: (3159, 16, 57)\n",
      "Flattened sequences shape: (3159, 912)\n",
      "Layer dims: [912, 135, 20, 3]\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 912)]        0           []                               \n",
      "                                                                                                  \n",
      " encoder_internal_0 (Dense)     (None, 135)          123255      ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " encoder_internal_1 (Dense)     (None, 20)           2720        ['encoder_internal_0[0][0]']     \n",
      "                                                                                                  \n",
      " encoder_mean (Dense)           (None, 3)            63          ['encoder_internal_1[0][0]']     \n",
      "                                                                                                  \n",
      " encoder_logvar (Dense)         (None, 3)            63          ['encoder_internal_1[0][0]']     \n",
      "                                                                                                  \n",
      " encoder_sampling (Lambda)      (None, 3)            0           ['encoder_mean[0][0]',           \n",
      "                                                                  'encoder_logvar[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 126,101\n",
      "Trainable params: 126,101\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 3)]               0         \n",
      "                                                                 \n",
      " decoder_internal_0 (Dense)  (None, 20)                80        \n",
      "                                                                 \n",
      " decoder_internal_1 (Dense)  (None, 135)               2835      \n",
      "                                                                 \n",
      " decoder_output (Dense)      (None, 912)               124032    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,947\n",
      "Trainable params: 126,947\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 912)]        0           []                               \n",
      "                                                                                                  \n",
      " encoder_internal_0 (Dense)     (None, 135)          123255      ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " encoder_internal_1 (Dense)     (None, 20)           2720        ['encoder_internal_0[0][0]']     \n",
      "                                                                                                  \n",
      " encoder_mean (Dense)           (None, 3)            63          ['encoder_internal_1[0][0]']     \n",
      "                                                                                                  \n",
      " encoder_logvar (Dense)         (None, 3)            63          ['encoder_internal_1[0][0]']     \n",
      "                                                                                                  \n",
      " encoder_sampling (Lambda)      (None, 3)            0           ['encoder_mean[0][0]',           \n",
      "                                                                  'encoder_logvar[0][0]']         \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 912)          126947      ['encoder_sampling[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 253,048\n",
      "Trainable params: 253,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 3159 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 15:42:14.776210: W tensorflow/c/c_api.cc:300] Operation '{name:'training/Adam/decoder_internal_1/bias/v/Assign' id:691 op device:{requested: '', assigned: ''} def:{{{node training/Adam/decoder_internal_1/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/decoder_internal_1/bias/v, training/Adam/decoder_internal_1/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3159/3159 [==============================] - 1s 215us/sample - loss: 98.3473\n",
      "Epoch 2/500\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 49.9972\n",
      "Epoch 3/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 48.5074\n",
      "Epoch 4/500\n",
      "3159/3159 [==============================] - 0s 128us/sample - loss: 47.2617\n",
      "Epoch 5/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 46.3679\n",
      "Epoch 6/500\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 45.5706\n",
      "Epoch 7/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 45.0120\n",
      "Epoch 8/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 44.6164\n",
      "Epoch 9/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 44.1705\n",
      "Epoch 10/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 43.7908\n",
      "Epoch 11/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 43.4103\n",
      "Epoch 12/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 43.0137\n",
      "Epoch 13/500\n",
      "3159/3159 [==============================] - 0s 138us/sample - loss: 42.6108\n",
      "Epoch 14/500\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 42.3315\n",
      "Epoch 15/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 42.1083\n",
      "Epoch 16/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 41.7154\n",
      "Epoch 17/500\n",
      "3159/3159 [==============================] - 0s 112us/sample - loss: 41.4708\n",
      "Epoch 18/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 41.3305\n",
      "Epoch 19/500\n",
      "3159/3159 [==============================] - 0s 124us/sample - loss: 41.0057\n",
      "Epoch 20/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 40.8246\n",
      "Epoch 21/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 40.6147\n",
      "Epoch 22/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 40.4238\n",
      "Epoch 23/500\n",
      "3159/3159 [==============================] - 0s 116us/sample - loss: 40.3126\n",
      "Epoch 24/500\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 40.0875\n",
      "Epoch 25/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 39.8592\n",
      "Epoch 26/500\n",
      "3159/3159 [==============================] - 0s 113us/sample - loss: 39.7467\n",
      "Epoch 27/500\n",
      "3159/3159 [==============================] - 0s 119us/sample - loss: 39.5279\n",
      "Epoch 28/500\n",
      "3159/3159 [==============================] - 0s 140us/sample - loss: 39.4813\n",
      "Epoch 29/500\n",
      "3159/3159 [==============================] - 0s 118us/sample - loss: 39.3286\n",
      "Epoch 30/500\n",
      "3159/3159 [==============================] - 0s 116us/sample - loss: 39.1680\n",
      "Epoch 31/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 38.9798\n",
      "Epoch 32/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 38.7852\n",
      "Epoch 33/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 38.6534\n",
      "Epoch 34/500\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 38.5092\n",
      "Epoch 35/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 38.5664\n",
      "Epoch 36/500\n",
      "3159/3159 [==============================] - 0s 126us/sample - loss: 38.2090\n",
      "Epoch 37/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 38.0953\n",
      "Epoch 38/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 38.0611\n",
      "Epoch 39/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 37.9223\n",
      "Epoch 40/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 37.8466\n",
      "Epoch 41/500\n",
      "3159/3159 [==============================] - 0s 115us/sample - loss: 37.7133\n",
      "Epoch 42/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 37.4826\n",
      "Epoch 43/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 37.3449\n",
      "Epoch 44/500\n",
      "3159/3159 [==============================] - 0s 135us/sample - loss: 37.2387\n",
      "Epoch 45/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 37.1219\n",
      "Epoch 46/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 37.0431\n",
      "Epoch 47/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 36.9214\n",
      "Epoch 48/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 36.8436\n",
      "Epoch 49/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 36.7573\n",
      "Epoch 50/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 36.5618\n",
      "Epoch 51/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 36.4992\n",
      "Epoch 52/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 36.3562\n",
      "Epoch 53/500\n",
      "3159/3159 [==============================] - 0s 113us/sample - loss: 36.3028\n",
      "Epoch 54/500\n",
      "3159/3159 [==============================] - 0s 130us/sample - loss: 36.1522\n",
      "Epoch 55/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 36.1407\n",
      "Epoch 56/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 35.9471\n",
      "Epoch 57/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 35.9325\n",
      "Epoch 58/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 35.8552\n",
      "Epoch 59/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 35.7263\n",
      "Epoch 60/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 35.5386\n",
      "Epoch 61/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 35.4013\n",
      "Epoch 62/500\n",
      "3159/3159 [==============================] - 0s 95us/sample - loss: 35.3091\n",
      "Epoch 63/500\n",
      "3159/3159 [==============================] - 0s 125us/sample - loss: 35.3588\n",
      "Epoch 64/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 35.3029\n",
      "Epoch 65/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 35.1706\n",
      "Epoch 66/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 35.0360\n",
      "Epoch 67/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 34.7499\n",
      "Epoch 68/500\n",
      "3159/3159 [==============================] - 0s 95us/sample - loss: 34.6404\n",
      "Epoch 69/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 34.6734\n",
      "Epoch 70/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 34.6012\n",
      "Epoch 71/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 34.5290\n",
      "Epoch 72/500\n",
      "3159/3159 [==============================] - 0s 134us/sample - loss: 34.3872\n",
      "Epoch 73/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 34.2612\n",
      "Epoch 74/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 34.4802\n",
      "Epoch 75/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 34.0691\n",
      "Epoch 76/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 34.0293\n",
      "Epoch 77/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 34.0161\n",
      "Epoch 78/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 33.9315\n",
      "Epoch 79/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 33.9452\n",
      "Epoch 80/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 34.0316\n",
      "Epoch 81/500\n",
      "3159/3159 [==============================] - 0s 135us/sample - loss: 33.6851\n",
      "Epoch 82/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 33.5618\n",
      "Epoch 83/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 33.4983\n",
      "Epoch 84/500\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 33.4224\n",
      "Epoch 85/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 33.3582\n",
      "Epoch 86/500\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 33.2906\n",
      "Epoch 87/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 33.1976\n",
      "Epoch 88/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 33.0354\n",
      "Epoch 89/500\n",
      "3159/3159 [==============================] - 0s 128us/sample - loss: 33.0259\n",
      "Epoch 90/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 33.0517\n",
      "Epoch 91/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 32.9875\n",
      "Epoch 92/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 32.8413\n",
      "Epoch 93/500\n",
      "3159/3159 [==============================] - 0s 94us/sample - loss: 32.6910\n",
      "Epoch 94/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 32.8385\n",
      "Epoch 95/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 32.6263\n",
      "Epoch 96/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 32.7488\n",
      "Epoch 97/500\n",
      "3159/3159 [==============================] - 0s 130us/sample - loss: 32.5352\n",
      "Epoch 98/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 32.4387\n",
      "Epoch 99/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 32.3378\n",
      "Epoch 100/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 32.5071\n",
      "Epoch 101/500\n",
      "3159/3159 [==============================] - 0s 94us/sample - loss: 32.4103\n",
      "Epoch 102/500\n",
      "3159/3159 [==============================] - 0s 94us/sample - loss: 32.0948\n",
      "Epoch 103/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 32.0670\n",
      "Epoch 104/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 32.1053\n",
      "Epoch 105/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 32.1073\n",
      "Epoch 106/500\n",
      "3159/3159 [==============================] - 0s 129us/sample - loss: 32.0064\n",
      "Epoch 107/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 32.0213\n",
      "Epoch 108/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 31.7468\n",
      "Epoch 109/500\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 31.7057\n",
      "Epoch 110/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 31.7003\n",
      "Epoch 111/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 31.6666\n",
      "Epoch 112/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 31.5855\n",
      "Epoch 113/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 31.7230\n",
      "Epoch 114/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 31.5348\n",
      "Epoch 115/500\n",
      "3159/3159 [==============================] - 0s 142us/sample - loss: 31.5520\n",
      "Epoch 116/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 31.5854\n",
      "Epoch 117/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 31.4200\n",
      "Epoch 118/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 31.3715\n",
      "Epoch 119/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 31.1954\n",
      "Epoch 120/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 31.0801\n",
      "Epoch 121/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 31.1019\n",
      "Epoch 122/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 31.2297\n",
      "Epoch 123/500\n",
      "3159/3159 [==============================] - 0s 131us/sample - loss: 30.9552\n",
      "Epoch 124/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 31.2074\n",
      "Epoch 125/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 31.0169\n",
      "Epoch 126/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 31.0721\n",
      "Epoch 127/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 30.7782\n",
      "Epoch 128/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 30.6843\n",
      "Epoch 129/500\n",
      "3159/3159 [==============================] - 0s 95us/sample - loss: 31.1441\n",
      "Epoch 130/500\n",
      "3159/3159 [==============================] - 0s 95us/sample - loss: 30.7904\n",
      "Epoch 131/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 30.6420\n",
      "Epoch 132/500\n",
      "3159/3159 [==============================] - 0s 131us/sample - loss: 30.4100\n",
      "Epoch 133/500\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 30.4427\n",
      "Epoch 134/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 30.5158\n",
      "Epoch 135/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 30.3435\n",
      "Epoch 136/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 30.2971\n",
      "Epoch 137/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 30.4418\n",
      "Epoch 138/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 30.2713\n",
      "Epoch 139/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 30.1540\n",
      "Epoch 140/500\n",
      "3159/3159 [==============================] - 0s 142us/sample - loss: 30.3148\n",
      "Epoch 141/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 30.1159\n",
      "Epoch 142/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 30.2059\n",
      "Epoch 143/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 30.2594\n",
      "Epoch 144/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 30.2249\n",
      "Epoch 145/500\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 30.1573\n",
      "Epoch 146/500\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 30.0557\n",
      "Epoch 147/500\n",
      "3159/3159 [==============================] - 0s 127us/sample - loss: 29.9555\n",
      "Epoch 148/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 29.8585\n",
      "Epoch 149/500\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 30.1198\n",
      "Epoch 150/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 30.1474\n",
      "Epoch 151/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 29.7407\n",
      "Epoch 152/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 29.8720\n",
      "Epoch 153/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 29.7127\n",
      "Epoch 154/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 29.5187\n",
      "Epoch 155/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 29.4751\n",
      "Epoch 156/500\n",
      "3159/3159 [==============================] - 0s 127us/sample - loss: 29.4721\n",
      "Epoch 157/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 29.6351\n",
      "Epoch 158/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 29.5247\n",
      "Epoch 159/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 29.7676\n",
      "Epoch 160/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 29.8522\n",
      "Epoch 161/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 29.5929\n",
      "Epoch 162/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 29.2369\n",
      "Epoch 163/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 29.4244\n",
      "Epoch 164/500\n",
      "3159/3159 [==============================] - 0s 130us/sample - loss: 29.3637\n",
      "Epoch 165/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 29.2605\n",
      "Epoch 166/500\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 29.3681\n",
      "Epoch 167/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 29.4500\n",
      "Epoch 168/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 29.5353\n",
      "Epoch 169/500\n",
      "3159/3159 [==============================] - 0s 95us/sample - loss: 29.7503\n",
      "Epoch 170/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 29.2421\n",
      "Epoch 171/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 29.0085\n",
      "Epoch 172/500\n",
      "3159/3159 [==============================] - 0s 125us/sample - loss: 29.0215\n",
      "Epoch 173/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 28.8489\n",
      "Epoch 174/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 28.8381\n",
      "Epoch 175/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 28.9632\n",
      "Epoch 176/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 28.9268\n",
      "Epoch 177/500\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 29.0829\n",
      "Epoch 178/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 29.1103\n",
      "Epoch 179/500\n",
      "3159/3159 [==============================] - 0s 132us/sample - loss: 28.9823\n",
      "Epoch 180/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 29.0536\n",
      "Epoch 181/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 28.8856\n",
      "Epoch 182/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 28.9365\n",
      "Epoch 183/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 28.7204\n",
      "Epoch 184/500\n",
      "3159/3159 [==============================] - 0s 94us/sample - loss: 28.8520\n",
      "Epoch 185/500\n",
      "3159/3159 [==============================] - 0s 93us/sample - loss: 28.7438\n",
      "Epoch 186/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 28.7566\n",
      "Epoch 187/500\n",
      "3159/3159 [==============================] - 0s 136us/sample - loss: 28.8052\n",
      "Epoch 188/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 28.5997\n",
      "Epoch 189/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 28.7080\n",
      "Epoch 190/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 28.6390\n",
      "Epoch 191/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 28.6072\n",
      "Epoch 192/500\n",
      "3159/3159 [==============================] - 0s 113us/sample - loss: 28.3366\n",
      "Epoch 193/500\n",
      "3159/3159 [==============================] - 0s 137us/sample - loss: 28.4584\n",
      "Epoch 194/500\n",
      "3159/3159 [==============================] - 0s 118us/sample - loss: 28.4639\n",
      "Epoch 195/500\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 28.5131\n",
      "Epoch 196/500\n",
      "3159/3159 [==============================] - 0s 119us/sample - loss: 28.2123\n",
      "Epoch 197/500\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 28.4309\n",
      "Epoch 198/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 28.4638\n",
      "Epoch 199/500\n",
      "3159/3159 [==============================] - 0s 149us/sample - loss: 28.1004\n",
      "Epoch 200/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 28.1554\n",
      "Epoch 201/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 28.4280\n",
      "Epoch 202/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 28.1851\n",
      "Epoch 203/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 27.9830\n",
      "Epoch 204/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 28.3344\n",
      "Epoch 205/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 28.4172\n",
      "Epoch 206/500\n",
      "3159/3159 [==============================] - 0s 136us/sample - loss: 28.3233\n",
      "Epoch 207/500\n",
      "3159/3159 [==============================] - 0s 128us/sample - loss: 28.1249\n",
      "Epoch 208/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 27.9076\n",
      "Epoch 209/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 28.1525\n",
      "Epoch 210/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 28.3765\n",
      "Epoch 211/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 28.0357\n",
      "Epoch 212/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 28.2660\n",
      "Epoch 213/500\n",
      "3159/3159 [==============================] - 0s 129us/sample - loss: 27.8097\n",
      "Epoch 214/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 27.7271\n",
      "Epoch 215/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 28.1267\n",
      "Epoch 216/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 27.9857\n",
      "Epoch 217/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 27.7488\n",
      "Epoch 218/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 28.1359\n",
      "Epoch 219/500\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 28.1245\n",
      "Epoch 220/500\n",
      "3159/3159 [==============================] - 0s 134us/sample - loss: 28.1087\n",
      "Epoch 221/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 27.8899\n",
      "Epoch 222/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 27.8528\n",
      "Epoch 223/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 27.5927\n",
      "Epoch 224/500\n",
      "3159/3159 [==============================] - 0s 93us/sample - loss: 27.5194\n",
      "Epoch 225/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 27.6855\n",
      "Epoch 226/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 27.6092\n",
      "Epoch 227/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 27.8219\n",
      "Epoch 228/500\n",
      "3159/3159 [==============================] - 0s 142us/sample - loss: 27.7171\n",
      "Epoch 229/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 27.6997\n",
      "Epoch 230/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 27.6109\n",
      "Epoch 231/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 27.7195\n",
      "Epoch 232/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 27.8470\n",
      "Epoch 233/500\n",
      "3159/3159 [==============================] - 0s 95us/sample - loss: 27.8134\n",
      "Epoch 234/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 27.3878\n",
      "Epoch 235/500\n",
      "3159/3159 [==============================] - 0s 135us/sample - loss: 27.3958\n",
      "Epoch 236/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 27.4280\n",
      "Epoch 237/500\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 28.1692\n",
      "Epoch 238/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 27.3191\n",
      "Epoch 239/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 27.4021\n",
      "Epoch 240/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 27.5174\n",
      "Epoch 241/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 27.2254\n",
      "Epoch 242/500\n",
      "3159/3159 [==============================] - 0s 133us/sample - loss: 27.5064\n",
      "Epoch 243/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 27.4493\n",
      "Epoch 244/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 27.3963\n",
      "Epoch 245/500\n",
      "3159/3159 [==============================] - 0s 95us/sample - loss: 27.3830\n",
      "Epoch 246/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 27.3572\n",
      "Epoch 247/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 27.2485\n",
      "Epoch 248/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 27.1363\n",
      "Epoch 249/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 27.6868\n",
      "Epoch 250/500\n",
      "3159/3159 [==============================] - 0s 135us/sample - loss: 27.2397\n",
      "Epoch 251/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 27.1024\n",
      "Epoch 252/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 27.0835\n",
      "Epoch 253/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 27.0714\n",
      "Epoch 254/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 27.1561\n",
      "Epoch 255/500\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 27.1405\n",
      "Epoch 256/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 27.0442\n",
      "Epoch 257/500\n",
      "3159/3159 [==============================] - 0s 129us/sample - loss: 27.6031\n",
      "Epoch 258/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 27.4101\n",
      "Epoch 259/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 27.0407\n",
      "Epoch 260/500\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 27.1847\n",
      "Epoch 261/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 27.1264\n",
      "Epoch 262/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 27.0107\n",
      "Epoch 263/500\n",
      "3159/3159 [==============================] - 0s 129us/sample - loss: 26.9457\n",
      "Epoch 264/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 27.3357\n",
      "Epoch 265/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 27.3930\n",
      "Epoch 266/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 27.0375\n",
      "Epoch 267/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 27.1822\n",
      "Epoch 268/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 26.7594\n",
      "Epoch 269/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 26.8236\n",
      "Epoch 270/500\n",
      "3159/3159 [==============================] - 0s 134us/sample - loss: 27.1822\n",
      "Epoch 271/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 27.0370\n",
      "Epoch 272/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 26.7430\n",
      "Epoch 273/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 26.7884\n",
      "Epoch 274/500\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 27.1221\n",
      "Epoch 275/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 26.8388\n",
      "Epoch 276/500\n",
      "3159/3159 [==============================] - 0s 131us/sample - loss: 26.7203\n",
      "Epoch 277/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 26.9969\n",
      "Epoch 278/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 27.1644\n",
      "Epoch 279/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 27.0097\n",
      "Epoch 280/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 26.4459\n",
      "Epoch 281/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 26.8808\n",
      "Epoch 282/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 26.4115\n",
      "Epoch 283/500\n",
      "3159/3159 [==============================] - 0s 129us/sample - loss: 26.5845\n",
      "Epoch 284/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 26.5621\n",
      "Epoch 285/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 26.6865\n",
      "Epoch 286/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 26.7738\n",
      "Epoch 287/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 26.5262\n",
      "Epoch 288/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 26.5878\n",
      "Epoch 289/500\n",
      "3159/3159 [==============================] - 0s 131us/sample - loss: 26.5460\n",
      "Epoch 290/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 26.6354\n",
      "Epoch 291/500\n",
      "3159/3159 [==============================] - 0s 118us/sample - loss: 26.6520\n",
      "Epoch 292/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 26.6893\n",
      "Epoch 293/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 27.1120\n",
      "Epoch 294/500\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 26.7596\n",
      "Epoch 295/500\n",
      "3159/3159 [==============================] - 0s 130us/sample - loss: 26.6533\n",
      "Epoch 296/500\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 27.0158\n",
      "Epoch 297/500\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 26.6477\n",
      "Epoch 298/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 26.5504\n",
      "Epoch 299/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 26.5051\n",
      "Epoch 300/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 26.3578\n",
      "Epoch 301/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 26.4001\n",
      "Epoch 302/500\n",
      "3159/3159 [==============================] - 0s 127us/sample - loss: 26.5891\n",
      "Epoch 303/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 26.4345\n",
      "Epoch 304/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 26.2867\n",
      "Epoch 305/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 26.1176\n",
      "Epoch 306/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 26.1221\n",
      "Epoch 307/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 26.2293\n",
      "Epoch 308/500\n",
      "3159/3159 [==============================] - 0s 131us/sample - loss: 26.4595\n",
      "Epoch 309/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 26.3938\n",
      "Epoch 310/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 26.2499\n",
      "Epoch 311/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 26.3907\n",
      "Epoch 312/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 26.6094\n",
      "Epoch 313/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 26.2882\n",
      "Epoch 314/500\n",
      "3159/3159 [==============================] - 0s 134us/sample - loss: 25.9512\n",
      "Epoch 315/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 26.3945\n",
      "Epoch 316/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 26.4533\n",
      "Epoch 317/500\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 26.5372\n",
      "Epoch 318/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 26.9821\n",
      "Epoch 319/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 26.7978\n",
      "Epoch 320/500\n",
      "3159/3159 [==============================] - 0s 95us/sample - loss: 26.1590\n",
      "Epoch 321/500\n",
      "3159/3159 [==============================] - 0s 123us/sample - loss: 25.9629\n",
      "Epoch 322/500\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 26.6138\n",
      "Epoch 323/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 26.1193\n",
      "Epoch 324/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 26.2309\n",
      "Epoch 325/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 26.4561\n",
      "Epoch 326/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 26.6401\n",
      "Epoch 327/500\n",
      "3159/3159 [==============================] - 0s 121us/sample - loss: 26.4470\n",
      "Epoch 328/500\n",
      "3159/3159 [==============================] - 0s 119us/sample - loss: 26.0740\n",
      "Epoch 329/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 25.9875\n",
      "Epoch 330/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 26.2342\n",
      "Epoch 331/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 26.1474\n",
      "Epoch 332/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 26.4118\n",
      "Epoch 333/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 26.0661\n",
      "Epoch 334/500\n",
      "3159/3159 [==============================] - 0s 125us/sample - loss: 26.1492\n",
      "Epoch 335/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 26.2299\n",
      "Epoch 336/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 25.8532\n",
      "Epoch 337/500\n",
      "3159/3159 [==============================] - 0s 116us/sample - loss: 25.8365\n",
      "Epoch 338/500\n",
      "3159/3159 [==============================] - 0s 120us/sample - loss: 26.0666\n",
      "Epoch 339/500\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 26.2791\n",
      "Epoch 340/500\n",
      "3159/3159 [==============================] - 0s 137us/sample - loss: 25.8285\n",
      "Epoch 341/500\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 26.1044\n",
      "Epoch 342/500\n",
      "3159/3159 [==============================] - 0s 113us/sample - loss: 25.9427\n",
      "Epoch 343/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 25.7541\n",
      "Epoch 344/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 26.0161\n",
      "Epoch 345/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 25.9686\n",
      "Epoch 346/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 26.1212\n",
      "Epoch 347/500\n",
      "3159/3159 [==============================] - 0s 127us/sample - loss: 26.1567\n",
      "Epoch 348/500\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 26.0833\n",
      "Epoch 349/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 25.9862\n",
      "Epoch 350/500\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 25.7414\n",
      "Epoch 351/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 26.0612\n",
      "Epoch 352/500\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 25.8831\n",
      "Epoch 353/500\n",
      "3159/3159 [==============================] - 0s 145us/sample - loss: 25.8437\n",
      "Epoch 354/500\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 25.6422\n",
      "Epoch 355/500\n",
      "3159/3159 [==============================] - 0s 113us/sample - loss: 26.3478\n",
      "Epoch 356/500\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 26.0486\n",
      "Epoch 357/500\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 25.7815\n",
      "Epoch 358/500\n",
      "3159/3159 [==============================] - 0s 132us/sample - loss: 25.8598\n",
      "Epoch 359/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 25.8276\n",
      "Epoch 360/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 25.5285\n",
      "Epoch 361/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 25.9913\n",
      "Epoch 362/500\n",
      "3159/3159 [==============================] - 0s 145us/sample - loss: 25.8217\n",
      "Epoch 363/500\n",
      "3159/3159 [==============================] - 1s 195us/sample - loss: 26.2412\n",
      "Epoch 364/500\n",
      "3159/3159 [==============================] - 0s 147us/sample - loss: 25.8662\n",
      "Epoch 365/500\n",
      "3159/3159 [==============================] - 0s 149us/sample - loss: 25.6201\n",
      "Epoch 366/500\n",
      "3159/3159 [==============================] - 0s 150us/sample - loss: 25.7890\n",
      "Epoch 367/500\n",
      "3159/3159 [==============================] - 0s 153us/sample - loss: 25.9582\n",
      "Epoch 368/500\n",
      "3159/3159 [==============================] - 1s 174us/sample - loss: 25.6797\n",
      "Epoch 369/500\n",
      "3159/3159 [==============================] - 0s 141us/sample - loss: 25.7300\n",
      "Epoch 370/500\n",
      "3159/3159 [==============================] - 0s 157us/sample - loss: 25.4796\n",
      "Epoch 371/500\n",
      "3159/3159 [==============================] - 0s 152us/sample - loss: 25.7466\n",
      "Epoch 372/500\n",
      "3159/3159 [==============================] - 1s 164us/sample - loss: 25.9453\n",
      "Epoch 373/500\n",
      "3159/3159 [==============================] - 0s 142us/sample - loss: 25.7246\n",
      "Epoch 374/500\n",
      "3159/3159 [==============================] - 0s 135us/sample - loss: 25.6039\n",
      "Epoch 375/500\n",
      "3159/3159 [==============================] - 0s 135us/sample - loss: 25.5744\n",
      "Epoch 376/500\n",
      "3159/3159 [==============================] - 1s 166us/sample - loss: 25.5805\n",
      "Epoch 377/500\n",
      "3159/3159 [==============================] - 0s 131us/sample - loss: 25.4742\n",
      "Epoch 378/500\n",
      "3159/3159 [==============================] - 0s 126us/sample - loss: 25.8453\n",
      "Epoch 379/500\n",
      "3159/3159 [==============================] - 0s 127us/sample - loss: 25.9684\n",
      "Epoch 380/500\n",
      "3159/3159 [==============================] - 1s 162us/sample - loss: 25.4203\n",
      "Epoch 381/500\n",
      "3159/3159 [==============================] - 0s 119us/sample - loss: 25.3966\n",
      "Epoch 382/500\n",
      "3159/3159 [==============================] - 0s 154us/sample - loss: 25.7282\n",
      "Epoch 383/500\n",
      "3159/3159 [==============================] - 0s 115us/sample - loss: 25.8128\n",
      "Epoch 384/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 25.4115\n",
      "Epoch 385/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 25.4679\n",
      "Epoch 386/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 25.6539\n",
      "Epoch 387/500\n",
      "3159/3159 [==============================] - 0s 131us/sample - loss: 25.9577\n",
      "Epoch 388/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 25.4375\n",
      "Epoch 389/500\n",
      "3159/3159 [==============================] - 0s 112us/sample - loss: 25.4746\n",
      "Epoch 390/500\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 25.6629\n",
      "Epoch 391/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 25.5022\n",
      "Epoch 392/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 25.5451\n",
      "Epoch 393/500\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 25.2701\n",
      "Epoch 394/500\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 25.4159\n",
      "Epoch 395/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 25.4525\n",
      "Epoch 396/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 25.2457\n",
      "Epoch 397/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 25.3720\n",
      "Epoch 398/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 25.3749\n",
      "Epoch 399/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 25.7837\n",
      "Epoch 400/500\n",
      "3159/3159 [==============================] - 0s 130us/sample - loss: 25.6386\n",
      "Epoch 401/500\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 25.5997\n",
      "Epoch 402/500\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 25.7006\n",
      "Epoch 403/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 25.1446\n",
      "Epoch 404/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 25.4768\n",
      "Epoch 405/500\n",
      "3159/3159 [==============================] - 0s 137us/sample - loss: 25.4309\n",
      "Epoch 406/500\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 25.4897\n",
      "Epoch 407/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 25.7949\n",
      "Epoch 408/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 25.3094\n",
      "Epoch 409/500\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 25.3779\n",
      "Epoch 410/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 25.2891\n",
      "Epoch 411/500\n",
      "3159/3159 [==============================] - 0s 137us/sample - loss: 25.0973\n",
      "Epoch 412/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 25.1559\n",
      "Epoch 413/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 25.2456\n",
      "Epoch 414/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 25.2547\n",
      "Epoch 415/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 25.6192\n",
      "Epoch 416/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 25.2955\n",
      "Epoch 417/500\n",
      "3159/3159 [==============================] - 0s 132us/sample - loss: 25.2980\n",
      "Epoch 418/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 25.4366\n",
      "Epoch 419/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 25.3588\n",
      "Epoch 420/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 25.3676\n",
      "Epoch 421/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 25.5138\n",
      "Epoch 422/500\n",
      "3159/3159 [==============================] - 0s 138us/sample - loss: 25.8517\n",
      "Epoch 423/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 25.6400\n",
      "Epoch 424/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 25.0787\n",
      "Epoch 425/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 24.8796\n",
      "Epoch 426/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 24.9201\n",
      "Epoch 427/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 25.1284\n",
      "Epoch 428/500\n",
      "3159/3159 [==============================] - 0s 132us/sample - loss: 25.0734\n",
      "Epoch 429/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 25.1904\n",
      "Epoch 430/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 24.9540\n",
      "Epoch 431/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 25.2320\n",
      "Epoch 432/500\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 25.2558\n",
      "Epoch 433/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 25.0830\n",
      "Epoch 434/500\n",
      "3159/3159 [==============================] - 0s 127us/sample - loss: 24.9524\n",
      "Epoch 435/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 25.2643\n",
      "Epoch 436/500\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 25.4070\n",
      "Epoch 437/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 25.7373\n",
      "Epoch 438/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 25.8381\n",
      "Epoch 439/500\n",
      "3159/3159 [==============================] - 0s 112us/sample - loss: 25.1889\n",
      "Epoch 440/500\n",
      "3159/3159 [==============================] - 0s 125us/sample - loss: 25.0955\n",
      "Epoch 441/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 24.8175\n",
      "Epoch 442/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 25.0960\n",
      "Epoch 443/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 25.3507\n",
      "Epoch 444/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 25.5344\n",
      "Epoch 445/500\n",
      "3159/3159 [==============================] - 0s 122us/sample - loss: 25.5464\n",
      "Epoch 446/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 25.4937\n",
      "Epoch 447/500\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 24.9601\n",
      "Epoch 448/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 24.9076\n",
      "Epoch 449/500\n",
      "3159/3159 [==============================] - 0s 99us/sample - loss: 25.1073\n",
      "Epoch 450/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 24.7138\n",
      "Epoch 451/500\n",
      "3159/3159 [==============================] - 0s 132us/sample - loss: 25.3131\n",
      "Epoch 452/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 25.4325\n",
      "Epoch 453/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 25.6312\n",
      "Epoch 454/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 25.3125\n",
      "Epoch 455/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 24.8602\n",
      "Epoch 456/500\n",
      "3159/3159 [==============================] - 0s 131us/sample - loss: 24.7805\n",
      "Epoch 457/500\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 24.8008\n",
      "Epoch 458/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 25.0497\n",
      "Epoch 459/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 24.8265\n",
      "Epoch 460/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 24.9218\n",
      "Epoch 461/500\n",
      "3159/3159 [==============================] - 0s 142us/sample - loss: 24.7350\n",
      "Epoch 462/500\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 24.6933\n",
      "Epoch 463/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 24.8801\n",
      "Epoch 464/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 24.9355\n",
      "Epoch 465/500\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 25.0970\n",
      "Epoch 466/500\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 25.5869\n",
      "Epoch 467/500\n",
      "3159/3159 [==============================] - 0s 133us/sample - loss: 25.3895\n",
      "Epoch 468/500\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 25.1355\n",
      "Epoch 469/500\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 24.8003\n",
      "Epoch 470/500\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 25.0097\n",
      "Epoch 471/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 24.9122\n",
      "Epoch 472/500\n",
      "3159/3159 [==============================] - 0s 129us/sample - loss: 24.7208\n",
      "Epoch 473/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 24.7059\n",
      "Epoch 474/500\n",
      "3159/3159 [==============================] - 0s 125us/sample - loss: 24.9572\n",
      "Epoch 475/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 25.0587\n",
      "Epoch 476/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 24.8912\n",
      "Epoch 477/500\n",
      "3159/3159 [==============================] - 0s 117us/sample - loss: 25.3122\n",
      "Epoch 478/500\n",
      "3159/3159 [==============================] - 0s 91us/sample - loss: 24.8433\n",
      "Epoch 479/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 24.6428\n",
      "Epoch 480/500\n",
      "3159/3159 [==============================] - 0s 92us/sample - loss: 24.7627\n",
      "Epoch 481/500\n",
      "3159/3159 [==============================] - 0s 92us/sample - loss: 24.9165\n",
      "Epoch 482/500\n",
      "3159/3159 [==============================] - 0s 92us/sample - loss: 25.0976\n",
      "Epoch 483/500\n",
      "3159/3159 [==============================] - 0s 118us/sample - loss: 25.1487\n",
      "Epoch 484/500\n",
      "3159/3159 [==============================] - 0s 97us/sample - loss: 25.0485\n",
      "Epoch 485/500\n",
      "3159/3159 [==============================] - 0s 94us/sample - loss: 24.7043\n",
      "Epoch 486/500\n",
      "3159/3159 [==============================] - 0s 95us/sample - loss: 24.7936\n",
      "Epoch 487/500\n",
      "3159/3159 [==============================] - 0s 96us/sample - loss: 25.0150\n",
      "Epoch 488/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 24.5828\n",
      "Epoch 489/500\n",
      "3159/3159 [==============================] - 0s 139us/sample - loss: 24.7663\n",
      "Epoch 490/500\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 24.5224\n",
      "Epoch 491/500\n",
      "3159/3159 [==============================] - 0s 100us/sample - loss: 24.5546\n",
      "Epoch 492/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 24.7669\n",
      "Epoch 493/500\n",
      "3159/3159 [==============================] - 0s 116us/sample - loss: 24.7088\n",
      "Epoch 494/500\n",
      "3159/3159 [==============================] - 0s 124us/sample - loss: 24.3778\n",
      "Epoch 495/500\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 24.9279\n",
      "Epoch 496/500\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 24.9379\n",
      "Epoch 497/500\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 24.9475\n",
      "Epoch 498/500\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 25.2081\n",
      "Epoch 499/500\n",
      "3159/3159 [==============================] - 0s 117us/sample - loss: 25.0235\n",
      "Epoch 500/500\n",
      "3159/3159 [==============================] - 0s 130us/sample - loss: 24.8620\n",
      "INFO:tensorflow:Assets written to: /var/folders/5w/xlkmsvyj2tscz43jpx6j7qt00000gn/T/tmp0qc3x8x2/assets\n",
      "Model is 509972 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 15:45:07.912327: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-07-08 15:45:07.912344: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-07-08 15:45:07.912759: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/5w/xlkmsvyj2tscz43jpx6j7qt00000gn/T/tmp0qc3x8x2\n",
      "2023-07-08 15:45:07.914152: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-07-08 15:45:07.914175: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/5w/xlkmsvyj2tscz43jpx6j7qt00000gn/T/tmp0qc3x8x2\n",
      "2023-07-08 15:45:07.919207: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-07-08 15:45:07.948489: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/5w/xlkmsvyj2tscz43jpx6j7qt00000gn/T/tmp0qc3x8x2\n",
      "2023-07-08 15:45:07.960159: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 47399 microseconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from xen.training.SequenceVAETrainer import SequenceVAETrainer\n",
    "\n",
    "trainer = SequenceVAETrainer(modelPath=\"../models\", modelName=\"mutopia_guitar_4-4\")\n",
    "trainer.loadSongDataset(\"../../../ai/trainingdata/music/mutopia_guitar/\", timesig='4/4', ticksPerQuarter=4, quartersPerMeasure=4, measuresPerSequence=1)\n",
    "\n",
    "trainer.createModel(latentDim = 3, hiddenLayers = 2)\n",
    "trainer.train(batchSize = 32, epochs = 500, learning_rate = 0.005)\n",
    "trainer.saveModel(quantize = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3159 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 16:02:31.158512: W tensorflow/c/c_api.cc:300] Operation '{name:'training_8/Adam/decoder_internal_0/bias/v/Assign' id:3134 op device:{requested: '', assigned: ''} def:{{{node training_8/Adam/decoder_internal_0/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_8/Adam/decoder_internal_0/bias/v, training_8/Adam/decoder_internal_0/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3159/3159 [==============================] - 1s 272us/sample - loss: 16.7425\n",
      "Epoch 2/1000\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 16.6732\n",
      "Epoch 3/1000\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 16.6591\n",
      "Epoch 4/1000\n",
      "3159/3159 [==============================] - 0s 151us/sample - loss: 16.5941\n",
      "Epoch 5/1000\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 16.5201\n",
      "Epoch 6/1000\n",
      "3159/3159 [==============================] - 0s 112us/sample - loss: 16.6005\n",
      "Epoch 7/1000\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 16.4369\n",
      "Epoch 8/1000\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 16.4225\n",
      "Epoch 9/1000\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 16.4590\n",
      "Epoch 10/1000\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 16.4472\n",
      "Epoch 11/1000\n",
      "3159/3159 [==============================] - 0s 116us/sample - loss: 16.4526\n",
      "Epoch 12/1000\n",
      "3159/3159 [==============================] - 0s 151us/sample - loss: 16.4464\n",
      "Epoch 13/1000\n",
      "3159/3159 [==============================] - 0s 112us/sample - loss: 16.4457\n",
      "Epoch 14/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3680\n",
      "Epoch 15/1000\n",
      "3159/3159 [==============================] - 0s 126us/sample - loss: 16.4422\n",
      "Epoch 16/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.4300\n",
      "Epoch 17/1000\n",
      "3159/3159 [==============================] - 0s 125us/sample - loss: 16.3774\n",
      "Epoch 18/1000\n",
      "3159/3159 [==============================] - 0s 126us/sample - loss: 16.3835\n",
      "Epoch 19/1000\n",
      "3159/3159 [==============================] - 0s 145us/sample - loss: 16.3698\n",
      "Epoch 20/1000\n",
      "3159/3159 [==============================] - 0s 119us/sample - loss: 16.4132\n",
      "Epoch 21/1000\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 16.3899\n",
      "Epoch 22/1000\n",
      "3159/3159 [==============================] - 0s 118us/sample - loss: 16.3933\n",
      "Epoch 23/1000\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 16.3429\n",
      "Epoch 24/1000\n",
      "3159/3159 [==============================] - 0s 119us/sample - loss: 16.3562\n",
      "Epoch 25/1000\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 16.4257\n",
      "Epoch 26/1000\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 16.3650\n",
      "Epoch 27/1000\n",
      "3159/3159 [==============================] - 0s 154us/sample - loss: 16.4032\n",
      "Epoch 28/1000\n",
      "3159/3159 [==============================] - 0s 115us/sample - loss: 16.3096\n",
      "Epoch 29/1000\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 16.3775\n",
      "Epoch 30/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3454\n",
      "Epoch 31/1000\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 16.3667\n",
      "Epoch 32/1000\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 16.4141\n",
      "Epoch 33/1000\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 16.3497\n",
      "Epoch 34/1000\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 16.3358\n",
      "Epoch 35/1000\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 16.3644\n",
      "Epoch 36/1000\n",
      "3159/3159 [==============================] - 0s 135us/sample - loss: 16.3692\n",
      "Epoch 37/1000\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 16.3856\n",
      "Epoch 38/1000\n",
      "3159/3159 [==============================] - 0s 113us/sample - loss: 16.4222\n",
      "Epoch 39/1000\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 16.3452\n",
      "Epoch 40/1000\n",
      "3159/3159 [==============================] - 0s 112us/sample - loss: 16.4016\n",
      "Epoch 41/1000\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 16.3776\n",
      "Epoch 42/1000\n",
      "3159/3159 [==============================] - 0s 112us/sample - loss: 16.3682\n",
      "Epoch 43/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3994\n",
      "Epoch 44/1000\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 16.3234\n",
      "Epoch 45/1000\n",
      "3159/3159 [==============================] - 0s 134us/sample - loss: 16.3595\n",
      "Epoch 46/1000\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 16.3307\n",
      "Epoch 47/1000\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 16.3044\n",
      "Epoch 48/1000\n",
      "3159/3159 [==============================] - 0s 113us/sample - loss: 16.4072\n",
      "Epoch 49/1000\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 16.4372\n",
      "Epoch 50/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3668\n",
      "Epoch 51/1000\n",
      "3159/3159 [==============================] - 0s 112us/sample - loss: 16.3809\n",
      "Epoch 52/1000\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 16.3474\n",
      "Epoch 53/1000\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 16.3814\n",
      "Epoch 54/1000\n",
      "3159/3159 [==============================] - 0s 141us/sample - loss: 16.2721\n",
      "Epoch 55/1000\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 16.4029\n",
      "Epoch 56/1000\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 16.3198\n",
      "Epoch 57/1000\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 16.3411\n",
      "Epoch 58/1000\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 16.2853\n",
      "Epoch 59/1000\n",
      "3159/3159 [==============================] - 0s 116us/sample - loss: 16.3761\n",
      "Epoch 60/1000\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 16.3565\n",
      "Epoch 61/1000\n",
      "3159/3159 [==============================] - 0s 115us/sample - loss: 16.2914\n",
      "Epoch 62/1000\n",
      "3159/3159 [==============================] - 0s 146us/sample - loss: 16.3262\n",
      "Epoch 63/1000\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 16.2978\n",
      "Epoch 64/1000\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 16.3336\n",
      "Epoch 65/1000\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 16.3307\n",
      "Epoch 66/1000\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 16.4065\n",
      "Epoch 67/1000\n",
      "3159/3159 [==============================] - 0s 126us/sample - loss: 16.3370\n",
      "Epoch 68/1000\n",
      "3159/3159 [==============================] - 0s 120us/sample - loss: 16.3113\n",
      "Epoch 69/1000\n",
      "3159/3159 [==============================] - 0s 122us/sample - loss: 16.3224\n",
      "Epoch 70/1000\n",
      "3159/3159 [==============================] - 0s 144us/sample - loss: 16.2891\n",
      "Epoch 71/1000\n",
      "3159/3159 [==============================] - 0s 119us/sample - loss: 16.3783\n",
      "Epoch 72/1000\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 16.3739\n",
      "Epoch 73/1000\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 16.3395\n",
      "Epoch 74/1000\n",
      "3159/3159 [==============================] - 0s 128us/sample - loss: 16.3027\n",
      "Epoch 75/1000\n",
      "3159/3159 [==============================] - 0s 119us/sample - loss: 16.3566\n",
      "Epoch 76/1000\n",
      "3159/3159 [==============================] - 0s 118us/sample - loss: 16.3842\n",
      "Epoch 77/1000\n",
      "3159/3159 [==============================] - 0s 119us/sample - loss: 16.3030\n",
      "Epoch 78/1000\n",
      "3159/3159 [==============================] - 0s 156us/sample - loss: 16.3025\n",
      "Epoch 79/1000\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 16.3179\n",
      "Epoch 80/1000\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 16.3345\n",
      "Epoch 81/1000\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 16.3197\n",
      "Epoch 82/1000\n",
      "3159/3159 [==============================] - 0s 120us/sample - loss: 16.3375\n",
      "Epoch 83/1000\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 16.3267\n",
      "Epoch 84/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3267\n",
      "Epoch 85/1000\n",
      "3159/3159 [==============================] - 0s 129us/sample - loss: 16.3729\n",
      "Epoch 86/1000\n",
      "3159/3159 [==============================] - 0s 115us/sample - loss: 16.3587\n",
      "Epoch 87/1000\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 16.3045\n",
      "Epoch 88/1000\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 16.3090\n",
      "Epoch 89/1000\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 16.4019\n",
      "Epoch 90/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3307\n",
      "Epoch 91/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3188\n",
      "Epoch 92/1000\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 16.3340\n",
      "Epoch 93/1000\n",
      "3159/3159 [==============================] - 0s 112us/sample - loss: 16.3497\n",
      "Epoch 94/1000\n",
      "3159/3159 [==============================] - 0s 134us/sample - loss: 16.3182\n",
      "Epoch 95/1000\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 16.3012\n",
      "Epoch 96/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.2993\n",
      "Epoch 97/1000\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 16.3153\n",
      "Epoch 98/1000\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 16.2704\n",
      "Epoch 99/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3232\n",
      "Epoch 100/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3878\n",
      "Epoch 101/1000\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 16.3040\n",
      "Epoch 102/1000\n",
      "3159/3159 [==============================] - 0s 144us/sample - loss: 16.2892\n",
      "Epoch 103/1000\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 16.3538\n",
      "Epoch 104/1000\n",
      "3159/3159 [==============================] - 0s 112us/sample - loss: 16.3355\n",
      "Epoch 105/1000\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 16.3272\n",
      "Epoch 106/1000\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 16.2674\n",
      "Epoch 107/1000\n",
      "3159/3159 [==============================] - 0s 116us/sample - loss: 16.3249\n",
      "Epoch 108/1000\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 16.2979\n",
      "Epoch 109/1000\n",
      "3159/3159 [==============================] - 0s 122us/sample - loss: 16.3265\n",
      "Epoch 110/1000\n",
      "3159/3159 [==============================] - 0s 142us/sample - loss: 16.2948\n",
      "Epoch 111/1000\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 16.3653\n",
      "Epoch 112/1000\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 16.3150\n",
      "Epoch 113/1000\n",
      "3159/3159 [==============================] - 0s 104us/sample - loss: 16.3167\n",
      "Epoch 114/1000\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 16.3341\n",
      "Epoch 115/1000\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 16.2753\n",
      "Epoch 116/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3540\n",
      "Epoch 117/1000\n",
      "3159/3159 [==============================] - 0s 116us/sample - loss: 16.3055\n",
      "Epoch 118/1000\n",
      "3159/3159 [==============================] - 0s 140us/sample - loss: 16.3457\n",
      "Epoch 119/1000\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 16.3683\n",
      "Epoch 120/1000\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 16.3493\n",
      "Epoch 121/1000\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 16.3056\n",
      "Epoch 122/1000\n",
      "3159/3159 [==============================] - 0s 128us/sample - loss: 16.4028\n",
      "Epoch 123/1000\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 16.3165\n",
      "Epoch 124/1000\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 16.3336\n",
      "Epoch 125/1000\n",
      "3159/3159 [==============================] - 0s 145us/sample - loss: 16.3278\n",
      "Epoch 126/1000\n",
      "3159/3159 [==============================] - 0s 115us/sample - loss: 16.3416\n",
      "Epoch 127/1000\n",
      "3159/3159 [==============================] - 0s 119us/sample - loss: 16.3607\n",
      "Epoch 128/1000\n",
      "3159/3159 [==============================] - 0s 126us/sample - loss: 16.3268\n",
      "Epoch 129/1000\n",
      "3159/3159 [==============================] - 0s 120us/sample - loss: 16.2549\n",
      "Epoch 130/1000\n",
      "3159/3159 [==============================] - 0s 115us/sample - loss: 16.2869\n",
      "Epoch 131/1000\n",
      "3159/3159 [==============================] - 0s 121us/sample - loss: 16.3053\n",
      "Epoch 132/1000\n",
      "3159/3159 [==============================] - 0s 156us/sample - loss: 16.2929\n",
      "Epoch 133/1000\n",
      "3159/3159 [==============================] - 0s 133us/sample - loss: 16.3393\n",
      "Epoch 134/1000\n",
      "3159/3159 [==============================] - 0s 120us/sample - loss: 16.3072\n",
      "Epoch 135/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3041\n",
      "Epoch 136/1000\n",
      "3159/3159 [==============================] - 1s 170us/sample - loss: 16.2892\n",
      "Epoch 137/1000\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 16.3388\n",
      "Epoch 138/1000\n",
      "3159/3159 [==============================] - 0s 113us/sample - loss: 16.2802\n",
      "Epoch 139/1000\n",
      "3159/3159 [==============================] - 0s 141us/sample - loss: 16.3576\n",
      "Epoch 140/1000\n",
      "3159/3159 [==============================] - 0s 116us/sample - loss: 16.3118\n",
      "Epoch 141/1000\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 16.2736\n",
      "Epoch 142/1000\n",
      "3159/3159 [==============================] - 0s 118us/sample - loss: 16.3201\n",
      "Epoch 143/1000\n",
      "3159/3159 [==============================] - 0s 125us/sample - loss: 16.2724\n",
      "Epoch 144/1000\n",
      "3159/3159 [==============================] - 0s 117us/sample - loss: 16.3276\n",
      "Epoch 145/1000\n",
      "3159/3159 [==============================] - 0s 112us/sample - loss: 16.2966\n",
      "Epoch 146/1000\n",
      "3159/3159 [==============================] - 1s 211us/sample - loss: 16.3017\n",
      "Epoch 147/1000\n",
      "3159/3159 [==============================] - 0s 133us/sample - loss: 16.3364\n",
      "Epoch 148/1000\n",
      "3159/3159 [==============================] - 0s 122us/sample - loss: 16.2638\n",
      "Epoch 149/1000\n",
      "3159/3159 [==============================] - 0s 113us/sample - loss: 16.3464\n",
      "Epoch 150/1000\n",
      "3159/3159 [==============================] - 0s 115us/sample - loss: 16.2940\n",
      "Epoch 151/1000\n",
      "3159/3159 [==============================] - 0s 133us/sample - loss: 16.2832\n",
      "Epoch 152/1000\n",
      "3159/3159 [==============================] - 0s 120us/sample - loss: 16.3008\n",
      "Epoch 153/1000\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 16.3481\n",
      "Epoch 154/1000\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 16.3404\n",
      "Epoch 155/1000\n",
      "3159/3159 [==============================] - 0s 110us/sample - loss: 16.3231\n",
      "Epoch 156/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3263\n",
      "Epoch 157/1000\n",
      "3159/3159 [==============================] - 0s 105us/sample - loss: 16.3210\n",
      "Epoch 158/1000\n",
      "3159/3159 [==============================] - 0s 115us/sample - loss: 16.3025\n",
      "Epoch 159/1000\n",
      "3159/3159 [==============================] - 1s 159us/sample - loss: 16.3713\n",
      "Epoch 160/1000\n",
      "3159/3159 [==============================] - 0s 129us/sample - loss: 16.2980\n",
      "Epoch 161/1000\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 16.3026\n",
      "Epoch 162/1000\n",
      "3159/3159 [==============================] - 0s 126us/sample - loss: 16.2844\n",
      "Epoch 163/1000\n",
      "3159/3159 [==============================] - 0s 113us/sample - loss: 16.3591\n",
      "Epoch 164/1000\n",
      "3159/3159 [==============================] - 0s 113us/sample - loss: 16.2661\n",
      "Epoch 165/1000\n",
      "3159/3159 [==============================] - 0s 157us/sample - loss: 16.2815\n",
      "Epoch 166/1000\n",
      "3159/3159 [==============================] - 0s 109us/sample - loss: 16.3383\n",
      "Epoch 167/1000\n",
      "3159/3159 [==============================] - 0s 101us/sample - loss: 16.2750\n",
      "Epoch 168/1000\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 16.3445\n",
      "Epoch 169/1000\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 16.3221\n",
      "Epoch 170/1000\n",
      "3159/3159 [==============================] - 0s 102us/sample - loss: 16.3454\n",
      "Epoch 171/1000\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 16.3913\n",
      "Epoch 172/1000\n",
      "3159/3159 [==============================] - 0s 133us/sample - loss: 16.2853\n",
      "Epoch 173/1000\n",
      "3159/3159 [==============================] - 0s 108us/sample - loss: 16.3052\n",
      "Epoch 174/1000\n",
      "3159/3159 [==============================] - 0s 106us/sample - loss: 16.3112\n",
      "Epoch 175/1000\n",
      "3159/3159 [==============================] - 0s 98us/sample - loss: 16.2961\n",
      "Epoch 176/1000\n",
      "3159/3159 [==============================] - 0s 117us/sample - loss: 16.2897\n",
      "Epoch 177/1000\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 16.2956\n",
      "Epoch 178/1000\n",
      "3159/3159 [==============================] - 0s 107us/sample - loss: 16.3298\n",
      "Epoch 179/1000\n",
      "3159/3159 [==============================] - 0s 134us/sample - loss: 16.2658\n",
      "Epoch 180/1000\n",
      "3159/3159 [==============================] - 0s 111us/sample - loss: 16.3213\n",
      "Epoch 181/1000\n",
      "3159/3159 [==============================] - 0s 130us/sample - loss: 16.2709\n",
      "Epoch 182/1000\n",
      "3159/3159 [==============================] - 0s 103us/sample - loss: 16.3020\n",
      "Epoch 183/1000\n",
      "3159/3159 [==============================] - 0s 114us/sample - loss: 16.2799\n",
      "Epoch 184/1000\n",
      "3159/3159 [==============================] - 0s 134us/sample - loss: 16.2642\n",
      "Epoch 185/1000\n",
      "2528/3159 [=======================>......] - ETA: 0s - loss: 16.3221"
     ]
    }
   ],
   "source": [
    "# Further training\n",
    "\n",
    "trainer.train(batchSize = 32, epochs = 1000, learning_rate = 0.0001)\n",
    "trainer.saveModel(quantize = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rob/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-07-08 15:55:38.647867: W tensorflow/c/c_api.cc:300] Operation '{name:'decoder/decoder_output/Sigmoid' id:205 op device:{requested: '', assigned: ''} def:{{{node decoder/decoder_output/Sigmoid}} = Sigmoid[T=DT_FLOAT, _has_manual_control_dependencies=true](decoder/decoder_output/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.85691674580563% recall\n"
     ]
    }
   ],
   "source": [
    "trainer.calcRecall()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plotLatentSpace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plotSequence(400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
