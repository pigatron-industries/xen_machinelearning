{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.12\n",
    "!pip install keras==2.12\n",
    "!pip install music21\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from music21 import converter, pitch, interval, instrument, note, stream\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from xen.visualise import plotPart, plotSparseNoteSequence\n",
    "from xen.data.songdata import SongDataSet\n",
    "\n",
    "data_dir = \"../../../ml_training/music/mutopia_guitar/\"\n",
    "\n",
    "dataset = SongDataSet()\n",
    "dataset.loadMidiDir(data_dir)\n",
    "\n",
    "print(f'Loaded {len(dataset.songs)} Songs') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.filterTimeSig('4/4')\n",
    "print(f'{len(dataset.songs)} Songs') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xen.data.codecs import SparseNoteSequenceCodec, FlatNoteSequenceCodec\n",
    "\n",
    "ticksPerQuarter = 4   # 4 = 16th notes, to allow triplets would need to be 12 = 48 per measure\n",
    "quartersPerMeasure = 4\n",
    "measuresPerSequence = 1\n",
    "\n",
    "codec = FlatNoteSequenceCodec(ticksPerQuarter, quartersPerMeasure, measuresPerSequence, '4/4')\n",
    "codec.encodeAll(dataset)\n",
    "\n",
    "print(dataset.sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from xen.models.VariationalAutoencoder import VariationalAutoEncoder\n",
    "\n",
    "autoencoder = VariationalAutoEncoder(layerDims=[dataset.sequences.shape[1], 256, 32, 4])\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "autoencoder.train(dataset.sequences, batchSize = 32, epochs = 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def countMatches(indata, outdata):\n",
    "    matches = 0\n",
    "    for i in range(0, len(indata)):\n",
    "        insequence = indata[i]\n",
    "        outsequence = outdata[i]\n",
    "        match = True\n",
    "        for j in range(len(insequence)):\n",
    "            if ((insequence[j] >= 0.5 and outsequence[j] < 0.5) or (insequence[j] < 0.5 and outsequence[j] >= 0.5)):\n",
    "                match = False\n",
    "                # print(i)\n",
    "        if (match):\n",
    "            matches = matches + 1\n",
    "    return matches\n",
    "    \n",
    "\n",
    "output = autoencoder.predict(dataset.sequences)\n",
    "\n",
    "matches = countMatches(dataset.sequences, output)\n",
    "print(f'{matches/len(dataset.sequences)*100}% recall')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latentdata = autoencoder.encode(dataset.sequences)\n",
    "sampling = np.array(latentdata[0])\n",
    "print(sampling[:,0])\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.scatter(sampling[:,0], sampling[:,1], color='b', marker='.')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.scatter(sampling[:,2], sampling[:,3], color='b', marker='.')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.scatter(sampling[:,4], sampling[:,5], color='b', marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "\n",
    "print(output.shape)\n",
    "\n",
    "\n",
    "plotSparseNoteSequence(codec.decode(dataset.sequences[index:index+1])[0])\n",
    "plotSparseNoteSequence(codec.decode(output[index:index+1])[0], threshold = 0.5)\n",
    "\n",
    "\n",
    "print(np.amax(output, axis = 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"timeSignature\": codec.timesignature,\n",
    "    \"sequenceLength\": ticksPerQuarter*quartersPerMeasure*measuresPerSequence\n",
    "}\n",
    "\n",
    "autoencoder.save(\"../models\", \"mutopia_guitar_4-4\", metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
